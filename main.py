# -*- coding: utf-8 -*-
"""Prompts_sending.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IivvetiX1tWtHIkh-9SBZDvGSZkoDDJg
"""

import requests
import json
from pathlib import Path
import pandas as pd
import time
from tqdm import tqdm

wait_between_requests = 2  # secondes
# Add here the api key of OpenRouter
api_key = ""

# Define models
models = ["google/gemma-3-12b-it",
          "mistralai/mistral-small-3.1-24b-instruct",
          "meta-llama/llama-3.2-3b-instruct",
          "microsoft/phi-4-reasoning:free",
          "qwen/qwen2.5-vl-32b-instruct:free",
          "openai/gpt-4o",
          "anthropic/claude-sonnet-4",
          "deepseek/deepseek-chat-v3-0324:free",
          "openai/gpt-4o-mini",
          "google/gemini-2.0-flash-001"]

test_models = ["openai/gpt-4o"]

error_model = ["qwen/qwen2.5-vl-32b-instruct:free"]

# Get the prompts - set the path to the prompt to use
folder_path = Path("/content/Prompt/Violation_DG")
if not folder_path.exists() or not any(folder_path.iterdir()):
    raise ValueError("The './Prompts_as_Text' folder is either empty or doesn't exist.")

file_contents = []
for file in folder_path.iterdir():
    if file.is_file():
        content = file.read_text(encoding='utf-8')
        file_contents.append((file.name, content))
        print(file.name)

def send_request(model, prompt):
    try:
        response = requests.post(
            url="https://openrouter.ai/api/v1/chat/completions",
            headers={"Authorization": f"Bearer {api_key}"},
            data=json.dumps({
                "model": model,
                "messages": [{"role": "user", "content": prompt}]
            })
        )
        if response.status_code != 200:
            return f"ERROR: {response.status_code} - {response.text}"
        return response.json().get("choices", [{}])[0].get("message", {}).get("content", "")
    except Exception as e:
        return f"ERROR: {str(e)}"

# Getting results for every model on every prompts
results = []
errors = []

print("Sending prompts to models...")
for name, prompt in tqdm(file_contents, desc="Fichiers"):
    for model in tqdm(models, desc="Mod√®les", leave=False):
        result_text = send_request(model, prompt)

        if result_text.startswith("ERROR:"):
            errors.append((model, name, result_text))
        else:
            results.append((model, name, result_text))

        time.sleep(wait_between_requests)

print("Saving to 'results.xlsx' and 'errors.xlsx'...")

if results:
    df_results = pd.DataFrame(results, columns=['model', 'filename', 'response'])
    pivot_df_results = df_results.pivot(index='filename', columns='model', values='response')
    pivot_df_results.to_excel('results.xlsx')

if errors:
    df_errors = pd.DataFrame(errors, columns=['model', 'filename', 'error'])
    pivot_df_errors = df_errors.pivot(index='filename', columns='model', values='error')
    pivot_df_errors.to_excel('errors.xlsx')

print("Done.")